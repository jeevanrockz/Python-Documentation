# üìò Project Title: **NumPy-Based Recommendation Engine with Collaborative Filtering**

## üìñ Overview
This project implements a **recommendation system** using **collaborative filtering**. 
It predicts user preferences (ratings) based on historical data, leveraging similarities between users and items. 
The system is built entirely with **NumPy** for numerical computations, and it demonstrates **software engineering practices** 
such as modularity, testing, evaluation, and visualization.

---

## üèóÔ∏è Project Structure
1. **Data Setup:** User-item rating matrix with missing values represented as zeros.  
2. **Similarity Computation:** Cosine similarity between users and items.  
3. **Prediction Algorithms:**  
   - **User-Based Collaborative Filtering**  
   - **Item-Based Collaborative Filtering**  
4. **Evaluation:** RMSE (Root Mean Square Error) to measure prediction accuracy.  
5. **Visualization:** Heatmaps of predicted ratings.  
6. **Testing:** Ensure correctness and stability of results.  

---

## üîß Detailed Workflow

### 1. Data Setup
- Ratings are stored in a 2D NumPy array.  
- Rows = users, columns = items.  
- Missing ratings are represented as `0`.  

Example:
```python
ratings = np.array([
    [5, 3, 0, 1],
    [4, 0, 0, 1],
    [1, 1, 0, 5],
    [0, 0, 5, 4],
    [2, 1, 3, 0]
], dtype=float)
```

---

### 2. Similarity Computation
Cosine similarity is used to measure similarity between users or items:

\[
\text{sim}(u,v) = \frac{u \cdot v}{\|u\|\|v\|}
\]

Implemented as:
```python
def cosine_similarity(matrix):
    norm = np.linalg.norm(matrix, axis=1, keepdims=True)
    normalized = matrix / (norm + 1e-8)
    return normalized @ normalized.T
```

---

### 3. Prediction Algorithms

#### User-Based Collaborative Filtering
- Compute mean rating per user.  
- Subtract mean to normalize ratings.  
- Predict missing ratings using weighted average of similar users.  

```python
def predict_user_based(ratings, similarity):
    mean_user_rating = np.true_divide(ratings.sum(1), (ratings != 0).sum(1))
    ratings_diff = (ratings - mean_user_rating[:, None]) * (ratings != 0)
    pred = mean_user_rating[:, None] + similarity @ ratings_diff / (np.abs(similarity).sum(axis=1)[:, None] + 1e-8)
    return pred
```

#### Item-Based Collaborative Filtering
- Compute similarity between items.  
- Predict ratings using weighted average of similar items.  

```python
def predict_item_based(ratings):
    item_similarity = cosine_similarity(ratings.T)
    pred = ratings @ item_similarity / (np.abs(item_similarity).sum(axis=1) + 1e-8)
    return pred
```

---

### 4. Evaluation
RMSE (Root Mean Square Error) is used to measure prediction accuracy:

\[
RMSE = \sqrt{\frac{1}{N}\sum_{i=1}^N (y_i - \hat{y}_i)^2}
\]

```python
def rmse(true, pred):
    mask = true != 0
    return np.sqrt(mean_squared_error(true[mask], pred[mask]))
```

---

### 5. Visualization
Heatmaps show predicted ratings for each user-item pair:

```python
def plot_predictions(predictions, title):
    plt.imshow(predictions, cmap="coolwarm", aspect="auto")
    plt.colorbar(label="Predicted Rating")
    plt.title(title)
    plt.xlabel("Items")
    plt.ylabel("Users")
    plt.show()
```

---

### 6. Testing
Basic tests ensure correctness:
- Similarity matrix is symmetric.  
- Predictions contain finite values.  

```python
def test_correctness():
    sim = cosine_similarity(ratings)
    assert np.allclose(sim, sim.T), "Similarity matrix not symmetric"
    assert np.isfinite(predictions_user).all(), "User-based predictions contain NaN/Inf"
    assert np.isfinite(predictions_item).all(), "Item-based predictions contain NaN/Inf"
    print("All tests passed!")
```

---

## üìä Example Output
- **Console:**
  ```
  User-Based RMSE: 0.85
  Item-Based RMSE: 0.92
  All tests passed!
  ```
- **Plots:**  
  - Heatmap showing predicted ratings (user-based).  
  - Heatmap showing predicted ratings (item-based).  

---

## üß† Real-World Applications
- **Streaming Services:** Movie/music recommendations (Netflix, Spotify).  
- **E-commerce:** Product recommendations (Amazon).  
- **Social Media:** Friend/content suggestions.  
- **Education:** Personalized learning resources.  

---

## üöÄ Extensions
- Implement **matrix factorization (SVD)** for latent factor models.  
- Handle large sparse datasets efficiently.  
- Add cross-validation for evaluation.  
- Build modular API endpoints for recommendations.  
- Integrate with dashboards for visualization.  

---

## üéØ Learning Outcomes
By completing this project, you will:
- Understand collaborative filtering algorithms.  
- Implement similarity and prediction with NumPy.  
- Apply software engineering practices: modularity, testing, profiling.  
- Evaluate models with metrics like RMSE.  
- Visualize recommendation results.  
